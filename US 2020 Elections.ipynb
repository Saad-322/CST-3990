{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de6be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib, pickle\n",
    "import tweepy as tw\n",
    "from textblob import TextBlob,Word\n",
    "from TSA_pipeline import *\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import GetOldTweets3 as got\n",
    "from datetime import datetime\n",
    "from matplotlib.dates import date2num\n",
    "from matplotlib import dates as mpl_dates\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,recall_score,f1_score,precision_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd55a455",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78effe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the entire csv file into panda data frames\n",
    "data_DT = pd.read_csv('TSA_datasets/US Elections 2020/hashtag_donaldtrump.csv',lineterminator='\\n', parse_dates=True)\n",
    "data_JB = pd.read_csv('TSA_datasets/US Elections 2020/hashtag_joebiden.csv',lineterminator='\\n', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdd564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the relevant columns from the datasets\n",
    "tweets_DT = pd.DataFrame(columns=['created_at','tweet','user_followers_count'],data=data_DT)\n",
    "tweets_JB = pd.DataFrame(columns=['created_at','tweet','user_followers_count'],data=data_JB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f750f06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "tweets_DT.rename(columns={'created_at':'Timestamp','tweet':'text'},inplace=True)\n",
    "tweets_JB.rename(columns={'created_at':'Timestamp','tweet':'text'},inplace=True)\n",
    "tweets_DT['tweet']=tweets_DT['text']\n",
    "tweets_JB['tweet']=tweets_JB['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0326ad8d",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc128914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectivity_filtering(df):\n",
    "    print('filtering data using subjectivity detection')\n",
    "    df=df[df['subjectivity']>=0.5]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acc8df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    print('transforming data')\n",
    "    \n",
    "    # vectorize\n",
    "    vectorizer = pickle.load(open(\"transformers/twitter/vectorizer.pickle\", \"rb\"))\n",
    "    feature_vector = vectorizer.transform(df['text'].astype(str))\n",
    "    \n",
    "    # defining variables\n",
    "    X_test = feature_vector\n",
    "    y_test = df['textblob']\n",
    "    \n",
    "    # select features\n",
    "    selector = pickle.load(open(\"transformers/twitter/selector.pickle\", \"rb\"))\n",
    "    X_test = selector.transform(X_test)\n",
    "    \n",
    "    return X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8dc162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_predictions(df):\n",
    "    print(\"Making predictions using bert-based model\")\n",
    "    # instantiate model\n",
    "    tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "    model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "    \n",
    "    # convert bert predictions between -1 and 1 as required for this comparative analysis\n",
    "    bert_predictions_converter = {\n",
    "        0:-1,\n",
    "        1:-0.5,\n",
    "        2:0,\n",
    "        3:0.5,\n",
    "        4:1\n",
    "    }\n",
    "    # make predictions one by one and pass through converter\n",
    "    df['bert'] = df['text'].apply(lambda x:bert_predictions_converter[int(torch.argmax((model(tokenizer.encode(x, return_tensors='pt'))).logits))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c941953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textblob_predictions(df):\n",
    "    print(\"Making TextBlob Predictions\")\n",
    "    # make Textblob predictions\n",
    "    df['textblob'] = df['text'].apply(lambda x: TextBlob(x).sentiment[0])\n",
    "    df['subjectivity'] = df['text'].apply(lambda x: TextBlob(x).sentiment[1])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bf332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make Textblob predictions\n",
    "tweets_DT = textblob_predictions(tweets_DT)\n",
    "    \n",
    "# apply subjectivity filtering\n",
    "tweets_DT = subjectivity_filtering(tweets_DT)\n",
    "print(len(tweets_DT))\n",
    "    \n",
    "# clean data\n",
    "tweets_DT = cleaning_data(tweets_DT)\n",
    "\n",
    "# transform into feature vector with selected features\n",
    "X_test, y_test = transform(tweets_DT)\n",
    "\n",
    "# Evaluation\n",
    "models = {}\n",
    "# models trained using the amazon Reviews Dataset\n",
    "# models['LR'] = joblib.load('models/final models/binary class/LR.pk1')\n",
    "# models['MNB'] = joblib.load('models/final models/binary class/MNB.pk1')\n",
    "# models['SVM'] = joblib.load('models/final models/binary class/SVM.pk1')\n",
    "# models['MLP'] = joblib.load('models/final models/binary class/MLP.pk1')\n",
    "\n",
    "# models trained using the Twitter Dataset\n",
    "models['LR'] = joblib.load('models/twitter/LR_new.pk1')\n",
    "models['MNB'] = joblib.load('models/twitter/MNB_new.pk1')\n",
    "models['SVM'] = joblib.load('models/twitter/SVM_new.pk1')\n",
    "models['MLP'] = joblib.load('models/twitter/MLP.pk1')\n",
    "for model in models.keys():\n",
    "    predictions = models[model].predict(X_test)\n",
    "    tweets_DT['predictions_{}'.format(model)] = predictions.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cc5022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make Textblob predictions\n",
    "textblob_predictions(tweets_JB)\n",
    "    \n",
    "# apply subjectivity filtering\n",
    "tweets_JB = subjectivity_filtering(tweets_JB)\n",
    "print(len(tweets_JB))\n",
    "    \n",
    "# clean data\n",
    "tweets_JB = cleaning_data(tweets_JB)\n",
    "\n",
    "# transform into feature vector with selected features\n",
    "X_test, y_test = transform(tweets_JB)\n",
    "\n",
    "# Evaluation\n",
    "models = {}\n",
    "# models trained using the amazon Reviews Dataset\n",
    "# models['LR'] = joblib.load('models/final models/binary class/LR.pk1')\n",
    "# models['MNB'] = joblib.load('models/final models/binary class/MNB.pk1')\n",
    "# models['SVM'] = joblib.load('models/final models/binary class/SVM.pk1')\n",
    "# models['MLP'] = joblib.load('models/final models/binary class/MLP.pk1')\n",
    "\n",
    "# models trained using the Twitter Dataset\n",
    "models['LR'] = joblib.load('models/twitter/LR_new.pk1')\n",
    "models['MNB'] = joblib.load('models/twitter/MNB_new.pk1')\n",
    "models['SVM'] = joblib.load('models/twitter/SVM_new.pk1')\n",
    "models['MLP'] = joblib.load('models/twitter/MLP.pk1')\n",
    "for model in models.keys():\n",
    "    predictions = models[model].predict(X_test)\n",
    "    tweets_JB['predictions_{}'.format(model)] = predictions.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991f1df3",
   "metadata": {},
   "source": [
    "### Rolling Mean Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11535e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_DT = tweets_DT.sort_values(by='Timestamp',ascending=True)\n",
    "polarity = {\n",
    "    'positive':1,\n",
    "    'negative':-1\n",
    "}\n",
    "rollingMean = 10000\n",
    "rollingMeanTB = 10000\n",
    "minPeriods = 100\n",
    "tweets_DT['predictions1_LR'] = tweets_DT['predictions_LR'].apply(lambda x:polarity[x])\n",
    "tweets_DT['predictions1_MNB'] = tweets_DT['predictions_MNB'].apply(lambda x:polarity[x])\n",
    "tweets_DT['predictions1_SVM'] = tweets_DT['predictions_SVM'].apply(lambda x:polarity[x])\n",
    "tweets_DT['predictions1_MLP'] = tweets_DT['predictions_MLP'].apply(lambda x:polarity[x])\n",
    "tweets_DT['rolling_LR'] = tweets_DT.predictions1_LR.rolling(rollingMean,min_periods=minPeriods).mean()\n",
    "tweets_DT['rolling_MNB'] = tweets_DT.predictions1_MNB.rolling(rollingMean,min_periods=minPeriods).mean()\n",
    "tweets_DT['rolling_SVM'] = tweets_DT.predictions1_SVM.rolling(rollingMean,min_periods=minPeriods).mean()\n",
    "tweets_DT['rolling_MLP'] = tweets_DT.predictions1_MLP.rolling(rollingMean,min_periods=minPeriods).mean()\n",
    "tweets_DT['rolling_TextBlob'] = tweets_DT.textblob.rolling(rollingMeanTB,min_periods=minPeriods).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6b41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_JB = tweets_JB.sort_values(by='Timestamp',ascending=True)\n",
    "polarity = {\n",
    "    'positive':1,\n",
    "    'negative':-1\n",
    "}\n",
    "rollingMean = 5000\n",
    "rollingMeanTB = 5000\n",
    "minPeriods = 100\n",
    "tweets_JB['predictions1_LR'] = tweets_JB['predictions_LR'].apply(lambda x:polarity[x])\n",
    "tweets_JB['predictions1_MNB'] = tweets_JB['predictions_MNB'].apply(lambda x:polarity[x])\n",
    "tweets_JB['predictions1_SVM'] = tweets_JB['predictions_SVM'].apply(lambda x:polarity[x])\n",
    "tweets_JB['predictions1_MLP'] = tweets_JB['predictions_MLP'].apply(lambda x:polarity[x])\n",
    "tweets_JB['rolling_LR'] = tweets_JB.predictions1_LR.rolling(rollingMean,min_periods=minPeriods).mean()\n",
    "tweets_JB['rolling_MNB'] = tweets_JB.predictions1_MNB.rolling(rollingMean,min_periods=minPeriods).mean()\n",
    "tweets_JB['rolling_SVM'] = tweets_JB.predictions1_SVM.rolling(rollingMean,min_periods=minPeriods).mean()\n",
    "tweets_JB['rolling_MLP'] = tweets_JB.predictions1_MLP.rolling(rollingMean,min_periods=minPeriods).mean()\n",
    "tweets_JB['rolling_TextBlob'] = tweets_JB.textblob.rolling(rollingMeanTB,min_periods=minPeriods).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a890c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string to datetime\n",
    "tweets_DT['Timestamp'] =  pd.to_datetime(tweets_DT['Timestamp'])\n",
    "tweets_JB['Timestamp'] =  pd.to_datetime(tweets_JB['Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fafc0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rolling_predictions_graphs(df,name):\n",
    "    # make 'Timestamp' the index\n",
    "    df_new =  df.copy()\n",
    "    df_new.set_index('Timestamp',inplace=True)\n",
    "\n",
    "    plt.figure(figsize=(14,7))\n",
    "    sns.lineplot(data=df_new[['rolling_LR','rolling_MNB','rolling_SVM','rolling_MLP','rolling_TextBlob']])\n",
    "    plt.legend(['LR','MNB','SVM','MLP','TextBlob'])\n",
    "    plt.xlabel(\"Date\",fontsize = 15)\n",
    "    plt.ylabel(\"Mean Sentiment\",fontsize = 15)\n",
    "    plt.title(name,fontsize = 20)\n",
    "    plt.gcf().autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697721db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rolling_predictions_graphs(tweets_DT,'Classifiers Comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9889af2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rolling_predictions_graphs(df,name,col):\n",
    "    # make 'Timestamp' the index\n",
    "    df_new =  df.copy()\n",
    "    df_new.set_index('Timestamp',inplace=True)\n",
    "    df_new['MLP'] = df_new['rolling_MLP']\n",
    "\n",
    "    plt.figure(figsize=(14,7))\n",
    "    sns.lineplot(data=df_new['MLP'],color=col)\n",
    "    plt.axvspan(date2num(datetime(2020,10,22)), date2num(datetime(2020,10,22)), \n",
    "           label=\"Last Presidential Debate\",color=col, alpha=0.2)\n",
    "    plt.axvspan(date2num(datetime(2020,11,3)), date2num(datetime(2020,11,3)), \n",
    "       label=\"Election Day\",color=col, alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Date\",fontsize = 15)\n",
    "    plt.ylabel(\"Mean Sentiment\",fontsize = 15)\n",
    "    plt.title(name,fontsize = 20)\n",
    "    plt.gcf().autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff6c2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_rolling_predictions_graphs(tweets_DT,'Trump','red')\n",
    "plot_rolling_predictions_graphs(tweets_JB,'Biden','blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489e7384",
   "metadata": {},
   "source": [
    "### positive / negative tweets examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3e7466",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(10):\n",
    "    print('\\n',tweets_JB[(tweets_JB['textblob']==1) & (tweets_JB['predictions1_MLP']==1)& (tweets_JB['predictions1_SVM']==1)& (tweets_JB['predictions1_MNB']==1)& (tweets_JB['predictions1_LR']==1)].tweet.values[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473059a0",
   "metadata": {},
   "source": [
    "### positive/negative/all table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213663fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_DT['predictions1_MLP'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c8f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_JB['predictions1_MLP'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7c2b6f",
   "metadata": {},
   "source": [
    "### The three Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f0e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Tweets per DAY\n",
    "def format_dataframes(df):\n",
    "    df = pd.DataFrame(data=df,columns=['Timestamp'])\n",
    "    df = df.reset_index()\n",
    "    df.drop('index',axis=1,inplace=True)\n",
    "    df = df.reset_index()\n",
    "    df['Timestamp'] = df['Timestamp'].dt.strftime('%m-%d')\n",
    "    df = df.groupby(['Timestamp'])['index'].count()\n",
    "    return df\n",
    "\n",
    "def tweets_per_day(sentiment):\n",
    "    if (sentiment=='Positive'):\n",
    "        sentiment_value = 1\n",
    "    else:\n",
    "        sentiment_value = -1\n",
    "    plt.figure(figsize=(14,7))\n",
    "    plt.xlabel(\"Date\",fontsize = 15)\n",
    "    plt.ylabel(\"Number of Tweets\",fontsize = 15)\n",
    "    plt.title('Number of Tweets per Day - {}'.format(sentiment),fontsize = 20)\n",
    "    sns.lineplot(data=format_dataframes(tweets_DT[tweets_DT['predictions1_MLP']==sentiment_value]),color='red')\n",
    "    sns.lineplot(data=format_dataframes(tweets_JB[tweets_JB['predictions1_MLP']==sentiment_value]),color='blue')\n",
    "    plt.legend(['Trump','Biden'])\n",
    "    plt.gcf().autofmt_xdate()\n",
    "\n",
    "tweets_per_day('Positive')\n",
    "tweets_per_day('Negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f9d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Tweets per HOUR\n",
    "def format_dataframes(df):\n",
    "    df = pd.DataFrame(data=df,columns=['Timestamp'])\n",
    "    df = df.reset_index()\n",
    "    df.drop('index',axis=1,inplace=True)\n",
    "    df = df.reset_index()\n",
    "    df['Timestamp'] = df['Timestamp'].dt.strftime('%m-%d-%H')\n",
    "    df = df.groupby(['Timestamp'])['index'].count()\n",
    "    df.index = pd.to_datetime(df.index,format='%m-%d-%H')\n",
    "    return df\n",
    "    \n",
    "def tweets_per_hour(sentiment):\n",
    "    if (sentiment=='Positive'):\n",
    "        sentiment_value = 1\n",
    "    else:\n",
    "        sentiment_value = -1\n",
    "    plt.figure(figsize=(20,7))\n",
    "    plt.xlabel(\"Date\",fontsize = 15)\n",
    "    plt.ylabel(\"Number of Tweets\",fontsize = 15)\n",
    "    plt.title('Number of Tweets per Hour - {}'.format(sentiment),fontsize = 20)\n",
    "    date_format = mpl_dates.DateFormatter('%m-%d')\n",
    "    sns.lineplot(data=format_dataframes(tweets_DT[tweets_DT['predictions1_MLP']==sentiment_value]),color='red')\n",
    "    sns.lineplot(data=format_dataframes(tweets_JB[tweets_JB['predictions1_MLP']==sentiment_value]),color='blue')\n",
    "    plt.gca().xaxis.set_major_formatter(date_format)\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.axvspan(date2num(datetime(1900,10,22)), date2num(datetime(1900,10,22)),color='green', alpha=0.9)\n",
    "    plt.axvspan(date2num(datetime(1900,11,3)), date2num(datetime(1900,11,3)),color='brown', alpha=0.9)\n",
    "    plt.legend(['Trump','Biden','Presidential Debate','Election Day'])\n",
    "    \n",
    "tweets_per_hour('Positive')\n",
    "tweets_per_hour('Negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadada02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative to Positive Ratio\n",
    "def format_dataframes(df,sentiment):\n",
    "    if (sentiment=='positive'):\n",
    "        sentiment_value = 1\n",
    "    else:\n",
    "        sentiment_value = -1\n",
    "    df = pd.DataFrame(data=df[df['predictions1_MLP']==sentiment_value],columns=['Timestamp'])\n",
    "    df = df.reset_index()\n",
    "    df.drop('index',axis=1,inplace=True)\n",
    "    df = df.reset_index()\n",
    "    df['Timestamp'] = df['Timestamp'].dt.strftime('%m-%d-%H')\n",
    "    df = df.groupby(['Timestamp'])['index'].count()\n",
    "    df.index = pd.to_datetime(df.index,format='%m-%d-%H')\n",
    "    df = df.to_frame()\n",
    "    df = df.reset_index()\n",
    "    if (sentiment=='positive'):\n",
    "        df.rename(columns={'index':'positive_count'},inplace=True)\n",
    "    else:\n",
    "        df.rename(columns={'index':'negative_count'},inplace=True)\n",
    "    return df\n",
    "\n",
    "def calculate_ratio(df):\n",
    "    df_positive = format_dataframes(df,'positive')\n",
    "    df_negative = format_dataframes(df,'negative')\n",
    "    df_final = df_positive\n",
    "    df_final['negative_count'] = df_negative['negative_count']\n",
    "    df_final['neg_to_pos_ratio'] = df_final['negative_count']/df_final['positive_count']\n",
    "    return df_final\n",
    "\n",
    "def plot_ratio_graph(df1,df2):\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.xlabel(\"Date\",fontsize = 15)\n",
    "    plt.ylabel(\"Negative to Positive Ratio\",fontsize = 15)\n",
    "    plt.title('Number of Tweets per Hour',fontsize = 20)\n",
    "    date_format = mpl_dates.DateFormatter('%m-%d')\n",
    "    sns.lineplot(x='Timestamp',y='neg_to_pos_ratio',data=df1,color='red')\n",
    "    sns.lineplot(x='Timestamp',y='neg_to_pos_ratio',data=df2,color='blue')\n",
    "    plt.gca().xaxis.set_major_formatter(date_format)\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.axvspan(date2num(datetime(1900,10,22)), date2num(datetime(1900,10,22)),color='green', alpha=0.9)\n",
    "    plt.axvspan(date2num(datetime(1900,11,3)), date2num(datetime(1900,11,3)),color='brown', alpha=0.9)\n",
    "    plt.legend(['Trump','Biden','Presidential Debate','Election Day'])\n",
    "    \n",
    "def plot_mean_graph(trump_ratio,biden_ratio):\n",
    "    trump_ratio['mean']=trump_ratio['neg_to_pos_ratio'].rolling(10,min_periods=10).mean()\n",
    "    biden_ratio['mean']=biden_ratio['neg_to_pos_ratio'].rolling(10,min_periods=10).mean()\n",
    "\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.xlabel(\"Date\",fontsize = 15)\n",
    "    plt.ylabel(\"Mean Negative to Positive Ratio\",fontsize = 15)\n",
    "    plt.title('Number of Tweets per Hour',fontsize = 20)\n",
    "    date_format = mpl_dates.DateFormatter('%m-%d')\n",
    "    sns.lineplot(x='Timestamp',y='mean',data=trump_ratio,color='red')\n",
    "    sns.lineplot(x='Timestamp',y='mean',data=biden_ratio,color='blue')\n",
    "    plt.gca().xaxis.set_major_formatter(date_format)\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.axvspan(date2num(datetime(1900,10,22)), date2num(datetime(1900,10,22)),color='green', alpha=0.9)\n",
    "    plt.axvspan(date2num(datetime(1900,11,3)), date2num(datetime(1900,11,3)),color='brown', alpha=0.9)\n",
    "    plt.legend(['Trump','Biden','Presidential Debate','Election Day'])\n",
    "\n",
    "trump_ratio = calculate_ratio(tweets_DT)\n",
    "biden_ratio = calculate_ratio(tweets_JB)\n",
    "biden_ratio = biden_ratio.drop(index=[22,23],axis=0)\n",
    "plot_ratio_graph(trump_ratio,biden_ratio)\n",
    "plot_mean_graph(trump_ratio,biden_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b77da5",
   "metadata": {},
   "source": [
    "### Pos/neg proportion graph for each candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9028623",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_DT[tweets_DT['Timestamp']<'2020-11-03'].predictions1_MLP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7e4698",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_JB[tweets_JB['Timestamp']<'2020-11-03'].predictions1_MLP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062e0158",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_elections_Trump = tweets_DT[tweets_DT['Timestamp']<'2020-11-03']\n",
    "before_elections_Biden = tweets_JB[tweets_JB['Timestamp']<'2020-11-03']\n",
    "dict = {\n",
    "    'Candidate' : ['Trump','Biden'],\n",
    "    'Positive' : [before_elections_Trump[before_elections_Trump['predictions1_MLP']==1].predictions1_MLP.count(),before_elections_Biden[before_elections_Biden['predictions1_MLP']==1].predictions1_MLP.count()],\n",
    "    'Negative' : [before_elections_Trump[before_elections_Trump['predictions1_MLP']==-1].predictions1_MLP.count(),before_elections_Biden[before_elections_Biden['predictions1_MLP']==-1].predictions1_MLP.count()],\n",
    "}\n",
    "df_percentage = pd.DataFrame.from_dict(dict)\n",
    "total = df_percentage['Positive'] + df_percentage['Negative']\n",
    "df_percentage['Positive'] = df_percentage['Positive'] / total\n",
    "df_percentage['Negative'] = df_percentage['Negative'] / total\n",
    "\n",
    "x = df_percentage.plot(kind='bar',x='Candidate',stacked=True,figsize=(14, 7),color=['limegreen','crimson'])\n",
    "plt.legend(ncol=2)\n",
    "plt.xlabel(\"Candidate\",fontsize=15)\n",
    "plt.ylabel(\"Proportion\",fontsize=15)\n",
    "plt.title('Overall Sentiment Proportion',fontsize=20)\n",
    "plt.gcf().autofmt_xdate()\n",
    "def with_hue(plot, feature, Number_of_categories, hue_categories):\n",
    "    a = [p.get_height() for p in plot.patches]\n",
    "    patch = [p for p in plot.patches]\n",
    "    for i in range(Number_of_categories):\n",
    "        total = feature.value_counts().values[i]\n",
    "        for j in range(hue_categories):\n",
    "            percentage = '{:.1f}%'.format(100 * a[(j*Number_of_categories + i)]/total)\n",
    "            x = patch[(j*Number_of_categories + i)].get_x() + patch[(j*Number_of_categories + i)].get_width() / 2 - 0.15\n",
    "            y = patch[(j*Number_of_categories + i)].get_y() + patch[(j*Number_of_categories + i)].get_height() \n",
    "            plot.annotate(percentage, (x, y), size = 15)\n",
    "with_hue(x,df_percentage.Candidate,2,2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958a0843",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_percentage.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa3077a",
   "metadata": {},
   "source": [
    "### Evaluation of Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41249f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make text blob positive/negative\n",
    "def textblob_converter(sentiment):\n",
    "    if(sentiment>0):\n",
    "        return int(1)\n",
    "    elif(sentiment<0):\n",
    "        return int(-1)\n",
    "    else:\n",
    "        return 0\n",
    "df_evaluation_DT = pd.DataFrame()\n",
    "df_evaluation_JB = pd.DataFrame()\n",
    "df_evaluation_DT['textblob'] = tweets_DT['textblob'].apply(lambda x:textblob_converter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa44441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all other classifiers\n",
    "df_evaluation_DT['LR'] = tweets_DT['predictions1_LR']\n",
    "df_evaluation_DT['MNB'] = tweets_DT['predictions1_MNB']\n",
    "df_evaluation_DT['SVM'] = tweets_DT['predictions1_SVM']\n",
    "df_evaluation_DT['MLP'] = tweets_DT['predictions1_MLP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e1e406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "\n",
    "# convert bert predictions between -1 and 1 as required for this comparative analysis\n",
    "bert_predictions_converter = {\n",
    "    0:-1,\n",
    "    1:-1,\n",
    "    2:0,\n",
    "    3:1,\n",
    "    4:1\n",
    "}\n",
    "# make predictions one by one and pass through converter\n",
    "df_evaluation_DT['bert'] = tweets_DT['tweet'].head(1000).apply(lambda x:bert_predictions_converter[int(torch.argmax((model(tokenizer.encode(x, return_tensors='pt'))).logits))])\n",
    "# drop null values because bert did't make all predictions\n",
    "df_evaluation_DT.dropna(inplace=True)\n",
    "# drop columns with 0\n",
    "df_evaluation_DT=df_evaluation_DT.loc[df_evaluation_DT['bert']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87176e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = ['LR','MNB','SVM','MLP']\n",
    "ground_truth_classifier = 'textblob'\n",
    "if (ground_truth_classifier=='textblob'):\n",
    "    df_evaluation_DT=df_evaluation_DT.loc[df_evaluation_DT['textblob']!=0]\n",
    "print('Accuracy')\n",
    "for classifier in classifiers:\n",
    "    print(classifier,': ',accuracy_score(df_evaluation_DT[ground_truth_classifier].values,df_evaluation_DT[classifier].values)*100,'%')\n",
    "\n",
    "print('Precision')\n",
    "for classifier in classifiers:\n",
    "    print(classifier,': ',precision_score(df_evaluation_DT[ground_truth_classifier].values,df_evaluation_DT[classifier].values,pos_label=1)*100,'%')\n",
    "    \n",
    "print('F-1 Score')\n",
    "for classifier in classifiers:\n",
    "    print(classifier,': ',f1_score(df_evaluation_DT[ground_truth_classifier].values,df_evaluation_DT[classifier].values,pos_label=1)*100,'%')\n",
    "  \n",
    "print('Recall')\n",
    "for classifier in classifiers:\n",
    "    print(classifier,': ',recall_score(df_evaluation_DT[ground_truth_classifier].values,df_evaluation_DT[classifier].values,pos_label=1)*100,'%')\n",
    "    \n",
    "# Confusion Matrix\n",
    "for classifier in classifiers:\n",
    "    cm = confusion_matrix(df_evaluation_DT[ground_truth_classifier].values,df_evaluation_DT[classifier].values,labels = [1,-1])\n",
    "    df_cm = pd.DataFrame(cm,columns=[1,-1],index = [1,-1])\n",
    "    for i in df_cm:\n",
    "        df_cm[i] = df_cm[i]/df_cm[i].sum()\n",
    "    print(classifier,'Confusion Matrix:','\\n',df_cm) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

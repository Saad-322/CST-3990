{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ae00793",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f563eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib, pickle\n",
    "import tweepy as tw\n",
    "from textblob import TextBlob,Word\n",
    "from TSA_pipeline import *\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import GetOldTweets3 as got\n",
    "from datetime import datetime\n",
    "from matplotlib.dates import date2num\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a35d7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"d2hXn9AgclF7xGx9u3QtAw4x0\"\n",
    "consumer_secret = \"O2u1AAst69VKOgKDhRstyLpjGpaYIwxsCSTiLeON4pACtZRbMy\"\n",
    "access_token = \"1491103209829679106-61ySETQ4bFkMnnDy23HBy68HTPvxUY\"\n",
    "access_secret = \"H9jOC3g5NstrawQBG61J5nOB96FdpwLqbAx7YG2tZYJn2\"\n",
    "auth = tw.OAuthHandler(consumer_key,consumer_secret)\n",
    "auth.set_access_token(access_token,access_secret)\n",
    "api = tw.API(auth,wait_on_rate_limit = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d50ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boris Johnson\n",
    "id = 1223365339494453248\n",
    "tweets = {}\n",
    "df_tweets = pd.DataFrame(columns=['text','Timestamp','id'])\n",
    "for index in range(5):\n",
    "    # USER SEARCH\n",
    "    handler = \"BorisJohnson\"\n",
    "    res = api.user_timeline(screen_name=handler,count=1000,max_id=id)\n",
    "\n",
    "    tweets = [{'text':tw.text,'Timestamp':tw.created_at, 'id':tw.id} for tw in res]\n",
    "    df_tweets = df_tweets.append(pd.DataFrame.from_dict(tweets))\n",
    "    id = tweets[len(tweets)-2]['id']\n",
    "    print(id)\n",
    "    tweets={}\n",
    "    \n",
    "df_tweets['sentiment'] = df_tweets['text'].apply(lambda x: TextBlob(x).sentiment[0])\n",
    "df_tweets['subjectivity'] = df_tweets['text'].apply(lambda x: TextBlob(x).sentiment[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8b9b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jeremy Corbyn\n",
    "id = 1222175012838412288\n",
    "tweets = {}\n",
    "df_tweets = pd.DataFrame(columns=['text','Timestamp','id'])\n",
    "for index in range(5):\n",
    "    # USER SEARCH\n",
    "    handler = \"jeremycorbyn\"\n",
    "    res = api.user_timeline(screen_name=handler,count=1000,max_id=id)\n",
    "\n",
    "    tweets = [{'text':tw.text,'Timestamp':tw.created_at, 'id':tw.id} for tw in res]\n",
    "    df_tweets = df_tweets.append(pd.DataFrame.from_dict(tweets))\n",
    "    id = tweets[len(tweets)-2]['id']\n",
    "    print(id)\n",
    "    tweets={}\n",
    "    \n",
    "df_tweets['sentiment'] = df_tweets['text'].apply(lambda x: TextBlob(x).sentiment[0])\n",
    "df_tweets['subjectivity'] = df_tweets['text'].apply(lambda x: TextBlob(x).sentiment[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd7610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectivity_filtering(df):\n",
    "    print('filtering data using subjectivity detection')\n",
    "    df=df[df['subjectivity']>0.4]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f7fdd0",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a52b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    print('transforming data')\n",
    "    \n",
    "    # vectorize\n",
    "    vectorizer = pickle.load(open(\"transformers/twitter/vectorizer.pickle\", \"rb\"))\n",
    "    feature_vector = vectorizer.transform(df['text'].astype(str))\n",
    "    \n",
    "    # defining variables\n",
    "    X_test = feature_vector\n",
    "    y_test = df['sentiment']\n",
    "    \n",
    "    # select features\n",
    "    selector = pickle.load(open(\"transformers/twitter/selector.pickle\", \"rb\"))\n",
    "    X_test = selector.transform(X_test)\n",
    "    \n",
    "    return X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da91224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_predictions(df):\n",
    "    # instantiate model\n",
    "    tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "    model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "    \n",
    "    # convert bert predictions between -1 and 1 as required for this comparative analysis\n",
    "    bert_predictions_converter = {\n",
    "        0:-1,\n",
    "        1:-0.5,\n",
    "        2:0,\n",
    "        3:0.5,\n",
    "        4:1\n",
    "    }\n",
    "    df['bert'] = df['text'].apply(lambda x:bert_predictions_converter[int(torch.argmax((model(tokenizer.encode(x, return_tensors='pt'))).logits))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e2c7b",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e3912",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_tweets.copy()\n",
    "print(len(df))\n",
    "\n",
    "df = subjectivity_filtering(df)\n",
    "print(len(df))\n",
    "\n",
    "# function to generate bert sentiment predictions\n",
    "bert_predictions(df)\n",
    "    \n",
    "# clean data\n",
    "df = cleaning_data(df)\n",
    "    \n",
    "# transform into feature vector with selected features\n",
    "X_test, y_test = transform(df)\n",
    "    \n",
    "# Evaluation\n",
    "models = {}\n",
    "# models['LR'] = joblib.load('models/final models/binary class/LR.pk1')\n",
    "# models['MNB'] = joblib.load('models/final models/binary class/MNB.pk1')\n",
    "# models['SVM'] = joblib.load('models/final models/binary class/SVM.pk1')\n",
    "models['LR'] = joblib.load('models/twitter/LR_new.pk1')\n",
    "models['MNB'] = joblib.load('models/twitter/MNB_new.pk1')\n",
    "models['SVM'] = joblib.load('models/twitter/SVM_new.pk1')\n",
    "models['MLP'] = joblib.load('models/twitter/MLP.pk1')\n",
    "for model in models.keys():\n",
    "    predictions = models[model].predict(X_test)\n",
    "    df['predictions_{}'.format(model)] = predictions.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c89e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df[['Timestamp','sentiment','bert','predictions_LR','predictions_MNB','predictions_SVM','predictions_MLP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7578c1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.sort_values(by='Timestamp',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45acdd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity = {\n",
    "    'positive':1,\n",
    "    'negative':-1\n",
    "}\n",
    "rollingMean = 50\n",
    "rollingMeanTB = 50\n",
    "minPeriods = 10\n",
    "df_final['predictions1_LR'] = df_final['predictions_LR'].apply(lambda x:polarity[x])\n",
    "df_final['predictions1_MNB'] = df_final['predictions_MNB'].apply(lambda x:polarity[x])\n",
    "df_final['predictions1_SVM'] = df_final['predictions_SVM'].apply(lambda x:polarity[x])\n",
    "df_final['predictions1_MLP'] = df_final['predictions_MLP'].apply(lambda x:polarity[x])\n",
    "df_final['rolling_LR'] = df_final.predictions1_LR.rolling(rollingMean,min_periods=minPeriods).mean()\n",
    "df_final['rolling_MNB'] = df_final.predictions1_MNB.rolling(rollingMean,min_periods=minPeriods).mean()\n",
    "df_final['rolling_SVM'] = df_final.predictions1_SVM.rolling(rollingMean,min_periods=minPeriods).mean()\n",
    "df_final['rolling_MLP'] = df_final.predictions1_MLP.rolling(rollingMean,min_periods=minPeriods).mean()\n",
    "df_final['rolling_TextBlob'] = df_final.sentiment.rolling(rollingMeanTB,min_periods=minPeriods).mean()\n",
    "df_final['rolling_Bert'] = df_final.bert.rolling(rollingMean,min_periods=minPeriods).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63674a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make 'Timestamp' the index\n",
    "df_final.set_index('Timestamp',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e342ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete duplicate rows where timestamp is same\n",
    "df_final = df_final.loc[~df_final.index.duplicated(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8169d576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling sentiment plot\n",
    "plt.figure(figsize=(14,10))\n",
    "plt.axvspan(date2num(datetime(2019,12,12)), date2num(datetime(2019,12,12)), \n",
    "           label=\"Election Day\",color=\"red\", alpha=0.8)\n",
    "plt.legend()\n",
    "sns.lineplot(x='Timestamp',y='rolling_MLP',data=df_final,color='blue',label=\"MLP\")\n",
    "sns.lineplot(x='Timestamp',y='rolling_TextBlob',data=df_final,color='black',label=\"TextBlob\")\n",
    "sns.lineplot(x='Timestamp',y='rolling_Bert',data=df_final,color='brown',label=\"Bert\")\n",
    "plt.xlabel(\"Date\",fontsize = 15)\n",
    "plt.ylabel(\"Mean Sentiment\",fontsize = 15)\n",
    "plt.title('Jeremy Corbyn Twitter Account',fontsize = 20)\n",
    "plt.gcf().autofmt_xdate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
